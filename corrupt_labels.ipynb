{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96f2cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid: 48 configs × 3 seeds = 144 runs\n",
      "cfg d=0.5, s=0.1, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8073 ± 0.0058\n",
      "cfg d=0.5, s=0.1, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.7913 ± 0.0017\n",
      "cfg d=0.5, s=0.1, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7723 ± 0.0133\n",
      "cfg d=0.5, s=0.1, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7067 ± 0.0196\n",
      "cfg d=0.5, s=0.1, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8207 ± 0.0034\n",
      "cfg d=0.5, s=0.1, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.8027 ± 0.0041\n",
      "cfg d=0.5, s=0.1, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7800 ± 0.0120\n",
      "cfg d=0.5, s=0.1, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7190 ± 0.0248\n",
      "cfg d=0.5, s=0.2, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8107 ± 0.0021\n",
      "cfg d=0.5, s=0.2, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.7947 ± 0.0012\n",
      "cfg d=0.5, s=0.2, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7707 ± 0.0116\n",
      "cfg d=0.5, s=0.2, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7130 ± 0.0139\n",
      "cfg d=0.5, s=0.2, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8200 ± 0.0024\n",
      "cfg d=0.5, s=0.2, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.8030 ± 0.0049\n",
      "cfg d=0.5, s=0.2, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7813 ± 0.0096\n",
      "cfg d=0.5, s=0.2, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7247 ± 0.0189\n",
      "cfg d=0.7, s=0.1, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8147 ± 0.0062\n",
      "cfg d=0.7, s=0.1, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.7947 ± 0.0094\n",
      "cfg d=0.7, s=0.1, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7757 ± 0.0106\n",
      "cfg d=0.7, s=0.1, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7130 ± 0.0156\n",
      "cfg d=0.7, s=0.1, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8193 ± 0.0012\n",
      "cfg d=0.7, s=0.1, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.8020 ± 0.0065\n",
      "cfg d=0.7, s=0.1, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7847 ± 0.0100\n",
      "cfg d=0.7, s=0.1, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7253 ± 0.0173\n",
      "cfg d=0.7, s=0.2, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8133 ± 0.0033\n",
      "cfg d=0.7, s=0.2, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.7987 ± 0.0105\n",
      "cfg d=0.7, s=0.2, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7773 ± 0.0111\n",
      "cfg d=0.7, s=0.2, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7200 ± 0.0136\n",
      "cfg d=0.7, s=0.2, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8177 ± 0.0042\n",
      "cfg d=0.7, s=0.2, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.7947 ± 0.0017\n",
      "cfg d=0.7, s=0.2, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7837 ± 0.0042\n",
      "cfg d=0.7, s=0.2, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7290 ± 0.0179\n",
      "cfg d=0.9, s=0.1, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8200 ± 0.0014\n",
      "cfg d=0.9, s=0.1, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.8077 ± 0.0033\n",
      "cfg d=0.9, s=0.1, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7743 ± 0.0192\n",
      "cfg d=0.9, s=0.1, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7253 ± 0.0152\n",
      "cfg d=0.9, s=0.1, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8210 ± 0.0073\n",
      "cfg d=0.9, s=0.1, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.8147 ± 0.0024\n",
      "cfg d=0.9, s=0.1, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7877 ± 0.0052\n",
      "cfg d=0.9, s=0.1, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7350 ± 0.0184\n",
      "cfg d=0.9, s=0.2, wd=0.0005, h=64, noise_rate=0.0 -> mean test 0.8177 ± 0.0037\n",
      "cfg d=0.9, s=0.2, wd=0.0005, h=64, noise_rate=0.1 -> mean test 0.8067 ± 0.0017\n",
      "cfg d=0.9, s=0.2, wd=0.0005, h=64, noise_rate=0.2 -> mean test 0.7843 ± 0.0038\n",
      "cfg d=0.9, s=0.2, wd=0.0005, h=64, noise_rate=0.3 -> mean test 0.7297 ± 0.0069\n",
      "cfg d=0.9, s=0.2, wd=0.005, h=64, noise_rate=0.0 -> mean test 0.8197 ± 0.0061\n",
      "cfg d=0.9, s=0.2, wd=0.005, h=64, noise_rate=0.1 -> mean test 0.8160 ± 0.0022\n",
      "cfg d=0.9, s=0.2, wd=0.005, h=64, noise_rate=0.2 -> mean test 0.7883 ± 0.0019\n",
      "cfg d=0.9, s=0.2, wd=0.005, h=64, noise_rate=0.3 -> mean test 0.7357 ± 0.0130\n",
      "\n",
      "Saved detailed runs to label_corruption_runs.csv\n",
      "Saved summary to label_corruption_summary.csv\n",
      "\n",
      "=== Top configs (by mean test acc) ===\n"
     ]
    }
   ],
   "source": [
    "# label_corrupt_data.py\n",
    "import os, random, time, csv, itertools\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Model: simple 2-layer GCN\n",
    "# ----------------------------\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_ch, hid_ch, out_ch, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_ch, hid_ch)\n",
    "        self.conv2 = GCNConv(hid_ch, out_ch)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x  # raw logits\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Utilities\n",
    "# ----------------------------\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def corrupt_labels(y, num_classes, noise_rate=0.0):\n",
    "    \"\"\"\n",
    "    Corrupts a portion of the labels with random incorrect labels.\n",
    "    \"\"\"\n",
    "    if noise_rate == 0.0:\n",
    "        return y\n",
    "    \n",
    "    y_corrupted = y.clone()\n",
    "    num_nodes = y.size(0)\n",
    "    \n",
    "    # Get a list of indices to be corrupted\n",
    "    corrupt_indices = torch.bernoulli(torch.full((num_nodes,), noise_rate)).bool()\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        if corrupt_indices[i]:\n",
    "            # Generate a new random label\n",
    "            new_label = torch.randint(0, num_classes, (1,), device=y.device)\n",
    "            # Ensure the new label is different from the original\n",
    "            while new_label == y[i]:\n",
    "                new_label = torch.randint(0, num_classes, (1,), device=y.device)\n",
    "            y_corrupted[i] = new_label\n",
    "            \n",
    "    return y_corrupted\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Train one run with label noise\n",
    "# ----------------------------\n",
    "def train_one_run(dataset_name=\"Cora\",\n",
    "                  hidden=64,\n",
    "                  dropout=0.5,\n",
    "                  weight_decay=5e-4,\n",
    "                  label_smoothing=0.0,\n",
    "                  noise_rate=0.0,\n",
    "                  lr=0.01,\n",
    "                  max_epochs=300,\n",
    "                  patience=50,\n",
    "                  seed=0,\n",
    "                  device=None,\n",
    "                  verbose=False):\n",
    "\n",
    "    set_seed(seed)\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataset = Planetoid(root=os.path.join(\"data\", dataset_name), name=dataset_name)\n",
    "    data = dataset[0].to(device)\n",
    "    \n",
    "    # Corrupt labels only for the training set\n",
    "    y_train_corrupted = corrupt_labels(data.y[data.train_mask], dataset.num_classes, noise_rate=noise_rate)\n",
    "\n",
    "    model = GCN(dataset.num_node_features, hidden, dataset.num_classes, dropout=dropout).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_test = 0.0\n",
    "    best_epoch = -1\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], y_train_corrupted)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluate with original labels\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out_eval = model(data.x, data.edge_index)\n",
    "            pred = out_eval.argmax(dim=1)\n",
    "            val_acc = (pred[data.val_mask] == data.y[data.val_mask]).float().mean().item()\n",
    "            test_acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean().item()\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_test = test_acc\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if verbose and epoch % 50 == 0:\n",
    "            print(f\"Seed {seed} | epoch {epoch} | loss {loss.item():.4f} | \"\n",
    "                  f\"val {val_acc:.4f} | test {test_acc:.4f}\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    return {\"best_val\": best_val, \"test_at_best\": best_test, \"best_epoch\": best_epoch}\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Grid search\n",
    "# ----------------------------\n",
    "def run_grid_search(\n",
    "    seeds=(0,1,2),\n",
    "    dropout_list=(0.5, 0.7, 0.9),\n",
    "    label_smooth_list=(0.1, 0.2),\n",
    "    weight_decay_list=(5e-4, 5e-3),\n",
    "    hidden_list=(64,),\n",
    "    noise_rate_list=(0.0, 0.1, 0.2),\n",
    "    dataset_name=\"Cora\",\n",
    "    max_epochs=300,\n",
    "    patience=50,\n",
    "    out_csv=\"label_corruption_results.csv\",\n",
    "    device=None,\n",
    "    verbose=False\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    combos = list(itertools.product(dropout_list, label_smooth_list, weight_decay_list, hidden_list, noise_rate_list))\n",
    "    print(f\"Running grid: {len(combos)} configs × {len(seeds)} seeds = {len(combos)*len(seeds)} runs\")\n",
    "\n",
    "    # CSV header\n",
    "    header = [\"dropout\", \"label_smoothing\", \"weight_decay\", \"hidden\", \"noise_rate\",\n",
    "              \"seed\", \"best_val\", \"test_at_best\", \"best_epoch\"]\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "\n",
    "    summary = OrderedDict()\n",
    "    for (dropout, lab_smooth, wd, hid, noise_rate) in combos:\n",
    "        cfg_key = (dropout, lab_smooth, wd, hid, noise_rate)\n",
    "        summary[cfg_key] = []\n",
    "\n",
    "        for seed in seeds:\n",
    "            res = train_one_run(\n",
    "                dataset_name=dataset_name,\n",
    "                hidden=hid,\n",
    "                dropout=dropout,\n",
    "                weight_decay=wd,\n",
    "                label_smoothing=lab_smooth,\n",
    "                noise_rate=noise_rate,\n",
    "                lr=0.01,\n",
    "                max_epochs=max_epochs,\n",
    "                patience=patience,\n",
    "                seed=seed,\n",
    "                device=device,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            with open(out_csv, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([dropout, lab_smooth, wd, hid, noise_rate, seed,\n",
    "                                 f\"{res['best_val']:.6f}\", f\"{res['test_at_best']:.6f}\",\n",
    "                                 res[\"best_epoch\"]])\n",
    "            summary[cfg_key].append(res[\"test_at_best\"])\n",
    "\n",
    "        arr = np.array(summary[cfg_key])\n",
    "        mean, std = arr.mean(), arr.std()\n",
    "        print(f\"cfg d={dropout}, s={lab_smooth}, wd={wd}, h={hid}, noise_rate={noise_rate} -> mean test {mean:.4f} ± {std:.4f}\")\n",
    "\n",
    "    rows = []\n",
    "    for k, vals in summary.items():\n",
    "        dropout, lab_smooth, wd, hid, noise_rate = k\n",
    "        arr = np.array(vals)\n",
    "        rows.append({\n",
    "            \"dropout\": dropout,\n",
    "            \"label_smoothing\": lab_smooth,\n",
    "            \"weight_decay\": wd,\n",
    "            \"hidden\": hid,\n",
    "            \"noise_rate\": noise_rate,\n",
    "            \"mean_test\": arr.mean(),\n",
    "            \"std_test\": arr.std(),\n",
    "            \"n_runs\": len(arr)\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(\"mean_test\", ascending=False).reset_index(drop=True)\n",
    "    df.to_csv(\"label_corruption_summary.csv\", index=False)\n",
    "    print(\"\\nSaved detailed runs to\", out_csv)\n",
    "    print(\"Saved summary to label_corruption_summary.csv\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Main entry\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    seeds = (0, 1, 2)\n",
    "    dropout_list = (0.5, 0.7, 0.9)\n",
    "    label_smooth_list = (0.1, 0.2)\n",
    "    weight_decay_list = (5e-4, 5e-3)\n",
    "    hidden_list = (64,)\n",
    "    noise_rate_list = (0.0, 0.1, 0.2, 0.3)\n",
    "\n",
    "    df_summary = run_grid_search(\n",
    "        seeds=seeds,\n",
    "        dropout_list=dropout_list,\n",
    "        label_smooth_list=label_smooth_list,\n",
    "        weight_decay_list=weight_decay_list,\n",
    "        hidden_list=hidden_list,\n",
    "        noise_rate_list=noise_rate_list,\n",
    "        dataset_name=\"Cora\",\n",
    "        max_epochs=300,\n",
    "        patience=50,\n",
    "        out_csv=\"label_corruption_runs.csv\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Top configs (by mean test acc) ===\")\n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
